# The path to a tab-delimited CSV file containing training data information formatted as | IMG_PATH | Transcription |
csv_path: ./data/example/labels.csv
# How much of the dataset should be used when testing and acquiring error rates
dataset_eval_size: 0.005
# The path to the pre-trained model weights
model_in: ./data/model_weights/example_model/run1
# The number of images in a mini-batch
batch_size: 2
# The max number of characters in a line-level transcription
max_seq_size: 128
# The size which all images will be resized - (height, width)
img_size: (64, 1024)

# String including the character set for the model (charset: abcd1234) If no characters are specified, the default is used.
charset:
# Whether or not to print examples to the console that contains predictions (using bp and wbs) and ground-truth labels
show_predictions: True

# Non-Punctuation character set (wbs_word_charset: '12345'). If not characters are specified, the default is used.
wbs_word_charset:
# Beam width use for wbs algorithm
wbs_beam_width: 15
# Word Beam Search dictionary file path, if not blank, the words in the file will be used to constrain the wbs algorithm
wbs_dictionary_path:
