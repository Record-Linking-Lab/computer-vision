# -*- coding: utf-8 -*-
"""Census_1870.py

Amber Oldroyd 
August 2021
oldroyd.amber@yahoo.com

This code gets the weights from the detectron model and segements images from the 1870 census.
Segments each of the 20 columns of the census

To use this code, edit the path to the weights, the number of classes in the detectron model, the directories, and the number of rows

Arguments:
    directory - this is the folder that contains d0-d999
    album - this is d0 - d999 where the images are stored

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mIW-AJM8WIYZkUpKKW6ucNNZqAP22cNZ
"""

# import some common libraries
import numpy as np
import cv2
import subprocess
import os 
import traceback
import sys

# Setup detectron2
import detectron2
from detectron2.utils.logger import setup_logger
setup_logger()
from detectron2 import model_zoo
from detectron2.engine import DefaultPredictor
from detectron2.config import get_cfg

#This cell creates the model from the final weights. Check to ensure it is downloading the correct weights from the model
cfg = get_cfg()

cfg.merge_from_file(model_zoo.get_config_file("COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml"))
cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512   

#make sure you change the number of classes
cfg.MODEL.ROI_HEADS.NUM_CLASSES = 21

cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, r"/fslhome/aoldroy2/fsl_groups/fslg_census/compute/projects/1870_census/1870_final_weights.pth")
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7  # set a custom testing threshold
predictor = DefaultPredictor(cfg)

def crop_image_from_box(img, boxes_np, iteration = 0, pixels = False, buffer = 50):
    """
    This crops the image based on the box given by the predictor (boxes_np)
    There is an optional buffer on the top and bottom. A buffer of 50 works well
    when using cropped_array to find the horizontal lines of the image 
    """
    left = int(boxes_np[iteration][0])
    top = int(boxes_np[iteration][1]) - buffer
    right = int(boxes_np[iteration][2])
    bottom = int(boxes_np[iteration][3]) + buffer
    cropped_array = img[top:bottom,left:right]
    if pixels == False:
      return cropped_array
    if pixels == True:
      return cropped_array, top, bottom, left, right

#This rotates an image by a specified angle in degrees.
def rotate_image(image, angle):
  image_center = tuple(np.array(image.shape[1::-1]) / 2)
  rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)
  result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)
  return result

def make_snippets(img, ys, rows = 41, pixels_on_either_side = 15, file_path = "", column = "edu"):
  pixels_per_row = int(img.shape[0]/rows)
  start = ys[0]
  im_end = ys[-1]

  for y in range(rows):
    try:
      finish = start + pixels_per_row
      x_check = start - pixels_on_either_side
      x_check2 = start + pixels_on_either_side
      y_check = finish - pixels_on_either_side
      y_check2 = finish + pixels_on_either_side
      newlist = [x for x in ys if (x > x_check) & (x < x_check2)]
      newlist2 = [x for x in ys if (x > y_check) & (x < y_check2)]
      if len(newlist)!=0:
        start = round(min(newlist))
      if len(newlist2)!=0:
        finish = round(max(newlist2))
      if y==rows-1:
        snippet=img[start:]
      elif y!=rows-1:
        snippet=img[start:finish+3]
      start = finish
      cv2.imwrite(file_path + "_box_" + column + "_row_" + str(y) + ".jpg", snippet)
    except:
      pass

#This code is adapted from Chris Johnson and Brandon Gill's code
# CODE THAT DOES THE SEGMENTATION
bad=[]

directory = sys.argv[1]
if directory[0] != "/":
    directory = "/" + directory
album = sys.argv[2]

os.chdir(directory + "/" +  album)
files = os.listdir()
for d in files:
    if d[-4:] == ".jpg":
      try:
        os.chdir(directory + "/" + album)
        im = cv2.imread(d)

        #There was rotating code that was here that I took out..

        #getting columns from image
        outputs = predictor(im)
      
        objects = outputs["instances"].pred_classes
        boxes = outputs["instances"].pred_boxes
        masks = outputs["instances"].pred_masks
        boxes_np = boxes.tensor.cpu().numpy()
        obj_np = objects.cpu().numpy()
        masks_np = masks.cpu().numpy()

        col_h, col_w, colors = im.shape

        for box in range(len(boxes_np)):
          cropped_array_orig, top, bottom, left, right = crop_image_from_box(im, boxes_np, iteration = box, pixels = True, buffer = 50) 

          #This section of the code turns everything white that wasn't identified as the column. 
          #This is not ideal because we need to see what is in the image, not just the stuff that was identified. People write outside of the lines and the outer info helps to identify the actual word.
          
          mask = masks_np[box][top:bottom,left:right]
          h , w = mask.shape
          white = np.zeros([h,w,3],dtype=np.uint8)
          white.fill(255)
          cropped_array_orig = (cropped_array_orig * mask[..., None]) + (white * ~mask[..., None]) #the ellipses selects all of the first dimension of the array, none of the second dimension
          
          #these next few lines add a buffer around sides of the box to aid in finding horizontal lines
          # (I moved the top to bottom buffer directly into the variables top and bottom for consistency in horizontal lines)
          if left<100:
            cropped_array = im[top:bottom,left:right+200]
          elif right + 100 > col_w:
            cropped_array = im[top:bottom,left-200:right]
          else:
            cropped_array = im[top:bottom,left-100:right+100]

          if cropped_array.shape[0] < cropped_array.shape[1]: #skips the header so it isn't segmented
            continue

          #cropped_array is used to find lines since it isn't whited out and is wider left to right
          #change to greyscale, add adaptive threshold, erode it 
          gray = cv2.cvtColor(cropped_array,cv2.COLOR_BGR2GRAY)
          edges = ~cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,219,2)

          kernel = np.ones((3, 30), np.uint8)                                                                # can be refined                                    
          th2 = cv2.erode(edges, kernel, iterations=1) #this finds the average color within the filter/kernel
          th3 = cv2.dilate(th2, kernel, iterations=1) #this accentuates the lines from the kernel

          length = int(cropped_array.shape[1]*.3) #length of the lines we are looking for                    # can be refined
          lines = cv2.HoughLines(th3,1,np.pi/180, length)

          # Getting Horizontal Lines to use if finding lines is bad in columns
          horizontal_keepers = []
          horizontal_keepers_combined = []
          for line in range(len(lines)):
            if lines[line][0][1]>1.54 and lines[line][0][1]<1.6: #if line is close to horizontal
              horizontal_keepers.append(lines[line])
 
          for n in range(len(horizontal_keepers)):
            a = np.cos(horizontal_keepers[n][0][1])
            b = np.sin(horizontal_keepers[n][0][1])
            x0 = a*horizontal_keepers[n][0][0]
            y0 = b*horizontal_keepers[n][0][0]
            if y0!=0:
              slope = -x0/y0
              intercept = int(y0 - x0*slope)
              side = int(slope * cropped_array.shape[1] + intercept)
              if abs(intercept - side)>25:
                pass
              else:
                horizontal_keepers_combined.append(intercept)
                horizontal_keepers_combined.append(side)

          #Crop top and bottom on lines
          horizontal_keepers_combined.sort()

          #I used a buffer of 50 on the top and bottom, so it makes sense to have the threshold be larger than 50
          lineBuffer = 60                                                                            # can be refined
          if horizontal_keepers_combined[0] < lineBuffer or horizontal_keepers_combined[1] < lineBuffer:
            #crop images at top
            col_top = int((horizontal_keepers_combined[1]+horizontal_keepers_combined[0])/2)
            cropped_array_orig=cropped_array_orig[col_top:,:]
            cropped_array=cropped_array[col_top:,:]
            horizontal_keepers_combined = [x-col_top for x in horizontal_keepers_combined]

          if  horizontal_keepers_combined[-1] > cropped_array.shape[0]-lineBuffer or horizontal_keepers_combined[-2] > cropped_array.shape[0]-lineBuffer:
            #only use lines in the range, crop images at the bottom
            col_bot = int((horizontal_keepers_combined[-1]+horizontal_keepers_combined[-2])/2)
            cropped_array=cropped_array[:col_bot,:]
            cropped_array_orig=cropped_array_orig[:col_bot,:]
            horizontal_keepers_combined = [x for x in horizontal_keepers_combined if x < col_bot] #shorten the list and get rid of extra numbers
          
          os.chdir("/fslhome/aoldroy2/fsl_groups/fslg_census/compute/projects/1870_census/imgs/segmented/snippets/" + album) #Path to save snipppets to 
          num_rows = 41                                                     ###-------CHANGE THIS, include the header if your labeling includes the header
          make_snippets(cropped_array_orig, horizontal_keepers_combined, rows = num_rows, pixels_on_either_side = 15, file_path = d[:-4], column= str(obj_np[box]))
      
      except:
        bad.append(d)
        traceback.print_exc() 
        print("image failed: " + d)
